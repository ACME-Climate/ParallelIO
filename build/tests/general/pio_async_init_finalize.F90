! DON'T MODIFY THIS FILE, ALL YOUR CHANGES WILL BE LOST
! This file is generated by ../../../tests/general/util/pio_tf_f90gen.pl
! from /home/tkurc/codar/e3sm/pio_adios1/ParallelIO/tests/general/pio_async_init_finalize.F90.in

! Split comm world into two comms (one with even procs and the other
! with odd procs
SUBROUTINE split_world_odd_even(new_comm, new_rank, new_size, is_even)   ! pio_async_init_finalize.F90.in:3
  use mpi   ! pio_async_init_finalize.F90.in:4
  use pio_tutil   ! pio_async_init_finalize.F90.in:5
  implicit none   ! pio_async_init_finalize.F90.in:6
  integer, intent(inout) :: new_comm   ! pio_async_init_finalize.F90.in:7
  integer, intent(inout) :: new_rank   ! pio_async_init_finalize.F90.in:8
  integer, intent(inout) :: new_size   ! pio_async_init_finalize.F90.in:9
  logical, intent(inout) :: is_even   ! pio_async_init_finalize.F90.in:10


  integer :: ierr   ! pio_async_init_finalize.F90.in:12
  integer :: color   ! pio_async_init_finalize.F90.in:13


  new_comm = MPI_COMM_NULL   ! pio_async_init_finalize.F90.in:15
  new_rank = 0   ! pio_async_init_finalize.F90.in:16
  new_size = 0   ! pio_async_init_finalize.F90.in:17


  if(mod(pio_tf_world_rank_, 2) == 0) then   ! pio_async_init_finalize.F90.in:19
    is_even = .true.   ! pio_async_init_finalize.F90.in:20
    color = 1   ! pio_async_init_finalize.F90.in:21
  else   ! pio_async_init_finalize.F90.in:22
    is_even = .false.   ! pio_async_init_finalize.F90.in:23
    color = 0   ! pio_async_init_finalize.F90.in:24
  end if   ! pio_async_init_finalize.F90.in:25


  call MPI_Comm_split(pio_tf_comm_, color, 0, new_comm, ierr)   ! pio_async_init_finalize.F90.in:27


  call MPI_Comm_rank(new_comm, new_rank, ierr)   ! pio_async_init_finalize.F90.in:29
  call MPI_Comm_size(new_comm, new_size, ierr)   ! pio_async_init_finalize.F90.in:30
END SUBROUTINE split_world_odd_even   ! pio_async_init_finalize.F90.in:31


! Split comm world into n disjoint comms
! The processes are divided evenly across the n comms
! gcomm_idx is a global index (among the comms) of the new_comm
! Note: The function assumes that there are atleast ncomms
! procs
SUBROUTINE split_world_ncomms(ncomms, new_comm, new_rank, new_size, gcomm_idx)   ! pio_async_init_finalize.F90.in:38
  use mpi   ! pio_async_init_finalize.F90.in:39
  use pio_tutil   ! pio_async_init_finalize.F90.in:40
  implicit none   ! pio_async_init_finalize.F90.in:41
  integer, intent(inout) :: ncomms   ! pio_async_init_finalize.F90.in:42
  integer, intent(inout) :: new_comm   ! pio_async_init_finalize.F90.in:43
  integer, intent(inout) :: new_rank   ! pio_async_init_finalize.F90.in:44
  integer, intent(inout) :: new_size   ! pio_async_init_finalize.F90.in:45
  integer, intent(inout) :: gcomm_idx   ! pio_async_init_finalize.F90.in:46


  integer :: nprocs_per_comm   ! pio_async_init_finalize.F90.in:48
  logical :: is_last_comm   ! pio_async_init_finalize.F90.in:49
  integer :: ierr   ! pio_async_init_finalize.F90.in:50
  integer :: color   ! pio_async_init_finalize.F90.in:51


  new_comm = MPI_COMM_NULL   ! pio_async_init_finalize.F90.in:53
  new_rank = 0   ! pio_async_init_finalize.F90.in:54
  new_size = 0   ! pio_async_init_finalize.F90.in:55
  gcomm_idx = 0   ! pio_async_init_finalize.F90.in:56


  ! We need at least one proc in each disjoint comm
  if(pio_tf_world_sz_ < ncomms) then   ! pio_async_init_finalize.F90.in:59
    return   ! pio_async_init_finalize.F90.in:60
  end if   ! pio_async_init_finalize.F90.in:61


  nprocs_per_comm = pio_tf_world_sz_/ncomms   ! pio_async_init_finalize.F90.in:63
  is_last_comm = .false.   ! pio_async_init_finalize.F90.in:64
  if(pio_tf_world_rank_ >= nprocs_per_comm * (ncomms - 1)) then   ! pio_async_init_finalize.F90.in:65
    is_last_comm = .true.   ! pio_async_init_finalize.F90.in:66
  end if   ! pio_async_init_finalize.F90.in:67


  color = pio_tf_world_rank_/nprocs_per_comm   ! pio_async_init_finalize.F90.in:69
  ! Make sure that every proc in the last set (all remaining procs
  ! are included in the last set/comm) gets the same color
  if(is_last_comm) then   ! pio_async_init_finalize.F90.in:72
    color = ncomms - 1   ! pio_async_init_finalize.F90.in:73
  end if   ! pio_async_init_finalize.F90.in:74
  gcomm_idx = color + 1   ! pio_async_init_finalize.F90.in:75


  call MPI_Comm_split(pio_tf_comm_, color, 0, new_comm, ierr)   ! pio_async_init_finalize.F90.in:77


  call MPI_Comm_size(new_comm, new_size, ierr)   ! pio_async_init_finalize.F90.in:79
  call MPI_Comm_rank(new_comm, new_rank, ierr)   ! pio_async_init_finalize.F90.in:80
END SUBROUTINE split_world_ncomms   ! pio_async_init_finalize.F90.in:81


! Async I/O as service test with 1 compute comm and an io comm
SUBROUTINE async_1comp_init_finalize
  USE pio_tutil
   ! pio_async_init_finalize.F90.in:84
  use mpi   ! pio_async_init_finalize.F90.in:85
  implicit none   ! pio_async_init_finalize.F90.in:86
  integer, parameter :: NUM_COMPONENTS = 1   ! pio_async_init_finalize.F90.in:87
  integer :: comp_comms(NUM_COMPONENTS)   ! pio_async_init_finalize.F90.in:88
  type(iosystem_desc_t) :: iosys(NUM_COMPONENTS)   ! pio_async_init_finalize.F90.in:89
  integer :: odd_even_comm, io_comm   ! pio_async_init_finalize.F90.in:90
  integer :: rank, sz, i   ! pio_async_init_finalize.F90.in:91
  logical :: is_even   ! pio_async_init_finalize.F90.in:92
  integer, parameter :: NUM_REARRANGERS = 2   ! pio_async_init_finalize.F90.in:93
  integer :: rearrs(NUM_REARRANGERS) = (/pio_rearr_subset,pio_rearr_box/)   ! pio_async_init_finalize.F90.in:94
  character(len=PIO_TF_MAX_STR_LEN) :: rearrs_info(NUM_REARRANGERS) = (/"PIO_REARR_SUBSET","PIO_REARR_BOX   "/)   ! pio_async_init_finalize.F90.in:95
  integer :: ret = PIO_NOERR   ! pio_async_init_finalize.F90.in:96


  do i=1,NUM_REARRANGERS   ! pio_async_init_finalize.F90.in:98

    IF (pio_tf_world_rank_ == 0) THEN
      IF (pio_tf_log_level_ >= 0) THEN
        WRITE(*,"(A)",ADVANCE="NO") "PIO_TF: "
        WRITE(*,*)  "Testing rearr : ", trim(rearrs_info(i))
      END IF
    END IF   ! pio_async_init_finalize.F90.in:99
    if(pio_tf_world_sz_ > 1) then   ! pio_async_init_finalize.F90.in:100
      ! Create two disjoint sets of IO procs and compute procs
      call split_world_odd_even(odd_even_comm, rank, sz, is_even)   ! pio_async_init_finalize.F90.in:102


      ! All even procs are compute procs and all odd procs are
      ! io procs
      if(is_even) then   ! pio_async_init_finalize.F90.in:106
        ! Compute proc
        comp_comms(1) = odd_even_comm   ! pio_async_init_finalize.F90.in:108
        io_comm = MPI_COMM_NULL   ! pio_async_init_finalize.F90.in:109
        call PIO_init(NUM_COMPONENTS, pio_tf_comm_, comp_comms, io_comm,&
              iosys, rearrs(i))   ! pio_async_init_finalize.F90.in:111
      else   ! pio_async_init_finalize.F90.in:112
        ! I/O proc
        comp_comms(1) = MPI_COMM_NULL   ! pio_async_init_finalize.F90.in:114
        io_comm = odd_even_comm   ! pio_async_init_finalize.F90.in:115
        call PIO_init(NUM_COMPONENTS, pio_tf_comm_, comp_comms, io_comm,&
              iosys, rearrs(i))   ! pio_async_init_finalize.F90.in:117
      end if   ! pio_async_init_finalize.F90.in:118
      ! Only compute procs call PIO function calls, I/O proc
      ! waits inside PIO_init() waiting for commands from the
      ! compute processes
      if(is_even) then   ! pio_async_init_finalize.F90.in:122
        call PIO_finalize(iosys(1), ret)   ! pio_async_init_finalize.F90.in:123
      end if   ! pio_async_init_finalize.F90.in:124
      call MPI_Comm_free(odd_even_comm, ret)   ! pio_async_init_finalize.F90.in:125
      
      IF (.NOT. (PIO_TF_Passert_((ret) == PIO_NOERR, pio_tf_comm_))) THEN
        pio_tf_retval_utest_ = -1
        IF (pio_tf_world_rank_ == 0) THEN
          PRINT *, "PIO_TF: PIO Function failed:",&
             "PIO_init()/Finalize() failed",&
            ":", __FILE__, ":", __LINE__,&
            "(pio_async_init_finalize.F90.in:126)"
        END IF
        RETURN
      END IF   ! pio_async_init_finalize.F90.in:126
    end if   ! pio_async_init_finalize.F90.in:127
  end do   ! pio_async_init_finalize.F90.in:128
END SUBROUTINE async_1comp_init_finalize   ! pio_async_init_finalize.F90.in:129




! Async I/O as service test with 1 compute comm and an io comm
! Multiple calls to PIO_init() with alternating compute and
! I/O procs
SUBROUTINE async_loop_init_finalize
  USE pio_tutil
   ! pio_async_init_finalize.F90.in:135
  use mpi   ! pio_async_init_finalize.F90.in:136
  implicit none   ! pio_async_init_finalize.F90.in:137
  integer, parameter :: NUM_LOOPS = 5   ! pio_async_init_finalize.F90.in:138
  integer, parameter :: NUM_COMPONENTS = 1   ! pio_async_init_finalize.F90.in:139
  integer :: comp_comms(NUM_COMPONENTS)   ! pio_async_init_finalize.F90.in:140
  type(iosystem_desc_t) :: iosys(NUM_COMPONENTS)   ! pio_async_init_finalize.F90.in:141
  integer :: odd_even_comm, io_comm   ! pio_async_init_finalize.F90.in:142
  integer :: rank, sz, i, k   ! pio_async_init_finalize.F90.in:143
  logical :: is_even, is_compute   ! pio_async_init_finalize.F90.in:144
  integer, parameter :: NUM_REARRANGERS = 2   ! pio_async_init_finalize.F90.in:145
  integer :: rearrs(NUM_REARRANGERS) = (/pio_rearr_subset,pio_rearr_box/)   ! pio_async_init_finalize.F90.in:146
  character(len=PIO_TF_MAX_STR_LEN) :: rearrs_info(NUM_REARRANGERS) = (/"PIO_REARR_SUBSET","PIO_REARR_BOX   "/)   ! pio_async_init_finalize.F90.in:147
  integer :: ret = PIO_NOERR   ! pio_async_init_finalize.F90.in:148


  do k=1,NUM_LOOPS   ! pio_async_init_finalize.F90.in:150
    do i=1,NUM_REARRANGERS   ! pio_async_init_finalize.F90.in:151

      IF (pio_tf_world_rank_ == 0) THEN
        IF (pio_tf_log_level_ >= 0) THEN
          WRITE(*,"(A)",ADVANCE="NO") "PIO_TF: "
          WRITE(*,*)  "Testing rearr : ", trim(rearrs_info(i))
        END IF
      END IF   ! pio_async_init_finalize.F90.in:152
      if(pio_tf_world_sz_ > 1) then   ! pio_async_init_finalize.F90.in:153
        ! Create two disjoint sets of IO procs and compute procs
        call split_world_odd_even(odd_even_comm, rank, sz, is_even)   ! pio_async_init_finalize.F90.in:155


        ! On even counts  : All even procs are compute procs and all
        !                     odd procs are io procs
        ! On odd counts   : All odd procs are compute procs and all
        !                     even procs are io procs
        is_compute = is_even   ! pio_async_init_finalize.F90.in:161
        if(mod(k, 2) /= 0) then   ! pio_async_init_finalize.F90.in:162
          is_compute = .not. is_even   ! pio_async_init_finalize.F90.in:163
        end if   ! pio_async_init_finalize.F90.in:164
        if(is_compute) then   ! pio_async_init_finalize.F90.in:165
          ! Compute proc
          comp_comms(1) = odd_even_comm   ! pio_async_init_finalize.F90.in:167
          io_comm = MPI_COMM_NULL   ! pio_async_init_finalize.F90.in:168
          call PIO_init(NUM_COMPONENTS, pio_tf_comm_, comp_comms, io_comm,&
                iosys, rearrs(i))   ! pio_async_init_finalize.F90.in:170
        else   ! pio_async_init_finalize.F90.in:171
          ! I/O proc
          comp_comms(1) = MPI_COMM_NULL   ! pio_async_init_finalize.F90.in:173
          io_comm = odd_even_comm   ! pio_async_init_finalize.F90.in:174
          call PIO_init(NUM_COMPONENTS, pio_tf_comm_, comp_comms, io_comm,&
                iosys, rearrs(i))   ! pio_async_init_finalize.F90.in:176
        end if   ! pio_async_init_finalize.F90.in:177
        ! Only compute procs call PIO function calls, I/O proc
        ! waits inside PIO_init() waiting for commands from the
        ! compute processes
        if(is_compute) then   ! pio_async_init_finalize.F90.in:181
          call PIO_finalize(iosys(1), ret)   ! pio_async_init_finalize.F90.in:182
        end if   ! pio_async_init_finalize.F90.in:183
        call MPI_Comm_free(odd_even_comm, ret)   ! pio_async_init_finalize.F90.in:184
        
        IF (.NOT. (PIO_TF_Passert_((ret) == PIO_NOERR, pio_tf_comm_))) THEN
          pio_tf_retval_utest_ = -1
          IF (pio_tf_world_rank_ == 0) THEN
            PRINT *, "PIO_TF: PIO Function failed:",&
               "PIO_init()/Finalize() failed",&
              ":", __FILE__, ":", __LINE__,&
              "(pio_async_init_finalize.F90.in:185)"
          END IF
          RETURN
        END IF   ! pio_async_init_finalize.F90.in:185
      end if   ! pio_async_init_finalize.F90.in:186
    end do   ! pio_async_init_finalize.F90.in:187
  end do   ! pio_async_init_finalize.F90.in:188
END SUBROUTINE async_loop_init_finalize   ! pio_async_init_finalize.F90.in:189


! Async I/O as service test with 2 compute comms and 1 io comm
SUBROUTINE async_2comp_init_finalize
  USE pio_tutil
   ! pio_async_init_finalize.F90.in:192
  use mpi   ! pio_async_init_finalize.F90.in:193
  implicit none   ! pio_async_init_finalize.F90.in:194
  ! Number of compute components
  integer, parameter :: NUM_COMPONENTS = 2   ! pio_async_init_finalize.F90.in:196
  ! Total number of comms = comms for each of NUM_COMPONENTS + io comm
  integer :: ncomms = NUM_COMPONENTS + 1   ! pio_async_init_finalize.F90.in:198
  ! We need to have at least one proc in each of comm
  integer, parameter :: MIN_NUM_PROCS = NUM_COMPONENTS + 1   ! pio_async_init_finalize.F90.in:200
  integer :: comp_comms(NUM_COMPONENTS)   ! pio_async_init_finalize.F90.in:201
  type(iosystem_desc_t) :: iosys(NUM_COMPONENTS)   ! pio_async_init_finalize.F90.in:202
  integer :: new_comm, io_comm   ! pio_async_init_finalize.F90.in:203
  integer :: new_rank, new_size, i, j   ! pio_async_init_finalize.F90.in:204
  ! gcomm_idx => Global index for the MPI comms
  ! gcomp_idx => Global index for the compute components
  integer :: gcomm_idx, gcomp_idx   ! pio_async_init_finalize.F90.in:207
  ! is_io == .true. if proc is part of the io comp
  logical :: is_io = .false.   ! pio_async_init_finalize.F90.in:209
  integer, parameter :: NUM_REARRANGERS = 2   ! pio_async_init_finalize.F90.in:210
  integer :: rearrs(NUM_REARRANGERS) = (/pio_rearr_subset,pio_rearr_box/)   ! pio_async_init_finalize.F90.in:211
  character(len=PIO_TF_MAX_STR_LEN) :: rearrs_info(NUM_REARRANGERS) = (/"PIO_REARR_SUBSET","PIO_REARR_BOX   "/)   ! pio_async_init_finalize.F90.in:212
  integer :: ret = PIO_NOERR   ! pio_async_init_finalize.F90.in:213


  do i=1,NUM_REARRANGERS   ! pio_async_init_finalize.F90.in:215

    IF (pio_tf_world_rank_ == 0) THEN
      IF (pio_tf_log_level_ >= 0) THEN
        WRITE(*,"(A)",ADVANCE="NO") "PIO_TF: "
        WRITE(*,*)  "Testing rearr : ", trim(rearrs_info(i))
      END IF
    END IF   ! pio_async_init_finalize.F90.in:216
    if(pio_tf_world_sz_ >= MIN_NUM_PROCS) then   ! pio_async_init_finalize.F90.in:217
      ! Create three disjoint sets of IO procs and compute procs
      call split_world_ncomms(ncomms, new_comm, new_rank, new_size, gcomm_idx)   ! pio_async_init_finalize.F90.in:219


      do j=1,NUM_COMPONENTS   ! pio_async_init_finalize.F90.in:221
        comp_comms(j) = MPI_COMM_NULL   ! pio_async_init_finalize.F90.in:222
      end do   ! pio_async_init_finalize.F90.in:223


      ! Use first comm as the IO proc
      is_io = .false.   ! pio_async_init_finalize.F90.in:226
      if(gcomm_idx == 1) then   ! pio_async_init_finalize.F90.in:227
        is_io = .true.   ! pio_async_init_finalize.F90.in:228
      end if   ! pio_async_init_finalize.F90.in:229
      gcomp_idx = gcomm_idx - 1   ! pio_async_init_finalize.F90.in:230


      if(is_io) then   ! pio_async_init_finalize.F90.in:232
        ! I/O proc
        io_comm = new_comm   ! pio_async_init_finalize.F90.in:234
        call PIO_init(NUM_COMPONENTS, pio_tf_comm_, comp_comms, io_comm,&
              iosys, rearrs(i))   ! pio_async_init_finalize.F90.in:236
      else   ! pio_async_init_finalize.F90.in:237
        ! Compute proc
        comp_comms(gcomp_idx) = new_comm   ! pio_async_init_finalize.F90.in:239
        io_comm = MPI_COMM_NULL   ! pio_async_init_finalize.F90.in:240
        call PIO_init(NUM_COMPONENTS, pio_tf_comm_, comp_comms, io_comm,&
              iosys, rearrs(i))   ! pio_async_init_finalize.F90.in:242
      end if   ! pio_async_init_finalize.F90.in:243
      ! Only compute procs call PIO function calls, I/O proc
      ! waits inside PIO_init() waiting for commands from the
      ! compute processes
      if(.not. is_io) then   ! pio_async_init_finalize.F90.in:247
        do j=1,NUM_COMPONENTS   ! pio_async_init_finalize.F90.in:248
          call PIO_finalize(iosys(j), ret)   ! pio_async_init_finalize.F90.in:249
        end do   ! pio_async_init_finalize.F90.in:250
      end if   ! pio_async_init_finalize.F90.in:251
      call MPI_Comm_free(new_comm, ret)   ! pio_async_init_finalize.F90.in:252
      
      IF (.NOT. (PIO_TF_Passert_((ret) == PIO_NOERR, pio_tf_comm_))) THEN
        pio_tf_retval_utest_ = -1
        IF (pio_tf_world_rank_ == 0) THEN
          PRINT *, "PIO_TF: PIO Function failed:",&
             "PIO_init()/Finalize() failed",&
            ":", __FILE__, ":", __LINE__,&
            "(pio_async_init_finalize.F90.in:253)"
        END IF
        RETURN
      END IF   ! pio_async_init_finalize.F90.in:253
    end if   ! pio_async_init_finalize.F90.in:254
  end do   ! pio_async_init_finalize.F90.in:255
END SUBROUTINE async_2comp_init_finalize   ! pio_async_init_finalize.F90.in:256




  SUBROUTINE PIO_TF_Test_driver_
    USE pio_tutil
    IMPLICIT NONE
    pio_tf_retval_utest_ = 0
    IF (pio_tf_world_rank_ == 0) THEN
      PRINT *, "PIO_TF: Starting async_1comp_init_finalize"
    END IF
    CALL async_1comp_init_finalize()
    IF (pio_tf_retval_utest_ /= 0) THEN
      pio_tf_nerrs_total_ = pio_tf_nerrs_total_ + 1
    END IF
    IF (pio_tf_world_rank_ == 0) THEN
      IF (pio_tf_retval_utest_ == 0) THEN
        WRITE(*,PIO_TF_TEST_RES_FMT) "PIO_TF:Test 1:",&
          "async_1comp_init_finalize","-----------", "PASSED"
      ELSE
        WRITE(*,PIO_TF_TEST_RES_FMT) "PIO_TF:Test 1:",&
          "async_1comp_init_finalize","-----------", "FAILED"
      END IF
    END IF
    pio_tf_retval_utest_ = 0
    IF (pio_tf_world_rank_ == 0) THEN
      PRINT *, "PIO_TF: Starting async_loop_init_finalize"
    END IF
    CALL async_loop_init_finalize()
    IF (pio_tf_retval_utest_ /= 0) THEN
      pio_tf_nerrs_total_ = pio_tf_nerrs_total_ + 1
    END IF
    IF (pio_tf_world_rank_ == 0) THEN
      IF (pio_tf_retval_utest_ == 0) THEN
        WRITE(*,PIO_TF_TEST_RES_FMT) "PIO_TF:Test 2:",&
          "async_loop_init_finalize","-----------", "PASSED"
      ELSE
        WRITE(*,PIO_TF_TEST_RES_FMT) "PIO_TF:Test 2:",&
          "async_loop_init_finalize","-----------", "FAILED"
      END IF
    END IF
    pio_tf_retval_utest_ = 0
    IF (pio_tf_world_rank_ == 0) THEN
      PRINT *, "PIO_TF: Starting async_2comp_init_finalize"
    END IF
    CALL async_2comp_init_finalize()
    IF (pio_tf_retval_utest_ /= 0) THEN
      pio_tf_nerrs_total_ = pio_tf_nerrs_total_ + 1
    END IF
    IF (pio_tf_world_rank_ == 0) THEN
      IF (pio_tf_retval_utest_ == 0) THEN
        WRITE(*,PIO_TF_TEST_RES_FMT) "PIO_TF:Test 3:",&
          "async_2comp_init_finalize","-----------", "PASSED"
      ELSE
        WRITE(*,PIO_TF_TEST_RES_FMT) "PIO_TF:Test 3:",&
          "async_2comp_init_finalize","-----------", "FAILED"
      END IF
    END IF
  END SUBROUTINE PIO_TF_Test_driver_


  PROGRAM PIO_TF_Test_main_
    USE pio_tutil
    IMPLICIT NONE
    INTEGER, PARAMETER :: NREARRS = 2
    INTEGER :: rearrs(NREARRS) = (/pio_rearr_subset,pio_rearr_box/)
    CHARACTER(LEN=PIO_TF_MAX_STR_LEN) :: rearrs_info(NREARRS) = (/"PIO_REARR_SUBSET","PIO_REARR_BOX   "/)
    INTEGER i, ierr

    pio_tf_nerrs_total_=0
    pio_tf_retval_utest_=0
    CALL MPI_Init(ierr)
    DO i=1,SIZE(rearrs)
      CALL PIO_TF_Init_(rearrs(i))
      IF (pio_tf_world_rank_ == 0) THEN
        WRITE(*,*) "PIO_TF: Testing : ", trim(rearrs_info(i))
      END IF
      CALL PIO_TF_Test_driver_()
      CALL PIO_TF_Finalize_()
    END DO
    IF (pio_tf_world_rank_ == 0) THEN
      IF (pio_tf_nerrs_total_ == 0) THEN
        IF (pio_tf_retval_utest_ == 0) THEN
          WRITE(*,PIO_TF_TEST_RES_FMT) "PIO_TF: ",&
           "All tests", "---------", "PASSED"
        ELSE
          pio_tf_nerrs_total_ = pio_tf_nerrs_total_ + 1
          WRITE(*,PIO_TF_TEST_RES_FMT) "PIO_TF: ",&
           "Test driver", "---------", "FAILED"
        END IF
      ELSE
        WRITE(*,PIO_TF_TEST_RES_FMT2) "PIO_TF:[",&
          pio_tf_nerrs_total_,"] Tests",&
          "----- FAILED"
      END IF
    END IF
    CALL MPI_Finalize(ierr)
    IF (pio_tf_nerrs_total_ /= 0) THEN
      STOP 99
    END IF
  END PROGRAM
